{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "#spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()\n",
    "#df = spark.read.csv('E:\\Saravanan\\AWS\\escalon\\Revenue_ServiceLine.json',header=True,escape=\"\\\"\")\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()\n",
    "df = spark.read.option(\"multiline\",\"true\").json('E:\\Saravanan\\AWS\\escalon\\JSON_Files\\customer_dt.json')\n",
    "#dff=df.select(\"Columns.Column.ColTitle\")\n",
    "#dff.show(truncate=False)\n",
    "dftax=df.select(explode(\"QueryResponse.Customer.Taxable\").alias(\"Taxable\"))\n",
    "dfid=df.select(explode(\"QueryResponse.Customer.BillAddr.Id\").alias(\"Id\"))\n",
    "dfline=df.select(explode(\"QueryResponse.Customer.BillAddr.Line1\").alias(\"Line1\"))\n",
    "dfcity=df.select(explode(\"QueryResponse.Customer.BillAddr.City\").alias(\"City\"))\n",
    "dfcount=df.select(explode(\"QueryResponse.Customer.BillAddr.CountrySubDivisionCode\").alias(\"CountrySubDivisionCode\"))\n",
    "dfpost=df.select(explode(\"QueryResponse.Customer.BillAddr.PostalCode\").alias(\"PostalCode\"))\n",
    "dflat=df.select(explode(\"QueryResponse.Customer.BillAddr.Lat\").alias(\"Lat\"))\n",
    "dflong=df.select(explode(\"QueryResponse.Customer.BillAddr.Long\").alias(\"Long\"))\n",
    "#unionAll(dftax, dfid, dfline).show()\n",
    "dffinal = dftax.withColumn(\"index\", monotonically_increasing_id()) \\\n",
    " .join(dfid.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dfline.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dfcity.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dfcount.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dfpost.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dflat.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .join(dflong.withColumn(\"index\", monotonically_increasing_id()), on=\"index\") \\\n",
    " .drop(\"index\")\n",
    "#dffinal.show(truncate=False)\n",
    "#dffinal.write.csv(\"E:\\Saravanan\\AWS\\escalon\\JSON_Files\\output.csv\")\n",
    "#dffinal.write.json(\"E:\\Saravanan\\AWS\\escalon\\JSON_Files\\output.json\")\n",
    "#dffinal.toPandas().to_csv(\"E:\\Saravanan\\AWS\\escalon\\JSON_Files\\output.csv\")\n",
    "\n",
    "dffinal.toPandas().to_json(\"E:\\Saravanan\\AWS\\escalon\\JSON_Files\\output.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
